{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/leocencetti/TF_object_detection/blob/master/TF_object_detection_training_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2Sgp4UQZdcV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yhzxsJb3dpWq"
   },
   "source": [
    "## Configs and Hyperparameters\n",
    "\n",
    "Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gnNXNQCjdniL"
   },
   "outputs": [],
   "source": [
    "# Repo link.\n",
    "repo_url = 'https://github.com/leocencetti/TF_object_detection'\n",
    "\n",
    "# Number of training steps.\n",
    "num_steps = 40000  # 200000\n",
    "\n",
    "# Number of evaluation steps.\n",
    "num_eval_steps = 500\n",
    "\n",
    "MODELS_CONFIG = {\n",
    "    'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
    "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
    "        'batch_size': 11\n",
    "    },\n",
    "    'faster_rcnn_inception_v2': {\n",
    "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
    "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
    "        'batch_size': 12\n",
    "    },\n",
    "    'rfcn_resnet101': {\n",
    "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
    "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
    "        'batch_size': 8\n",
    "    }\n",
    "}\n",
    "\n",
    "# Pick the model you want to use\n",
    "# Select a model in `MODELS_CONFIG`.\n",
    "selected_model = 'faster_rcnn_inception_v2'\n",
    "\n",
    "# Name of the object detection model to use.\n",
    "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
    "\n",
    "# Name of the pipline file in tensorflow object detection API.\n",
    "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
    "\n",
    "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
    "batch_size = MODELS_CONFIG[selected_model]['batch_size']\n",
    "\n",
    "# Training input tensor size\n",
    "img_height = 544\n",
    "img_width = 960"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w4V-XE6kbkc1"
   },
   "source": [
    "## Clone the `TF_object_detection` repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dxc3DmvLQF3z"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%cd /content\n",
    "\n",
    "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
    "\n",
    "!git clone {repo_url}\n",
    "%cd {repo_dir_path}\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libbsd0 libice6 libpthread-stubs0-dev libx11-6 libx11-data libx11-dev\n",
      "  libx11-doc libxau-dev libxau6 libxcb1 libxcb1-dev libxdmcp-dev libxdmcp6\n",
      "  libxrender1 x11-common x11proto-core-dev x11proto-dev xorg-sgml-doctools\n",
      "  xtrans-dev\n",
      "Suggested packages:\n",
      "  libxcb-doc\n",
      "The following NEW packages will be installed:\n",
      "  libbsd0 libice6 libpthread-stubs0-dev libsm6 libx11-6 libx11-data libx11-dev\n",
      "  libx11-doc libxau-dev libxau6 libxcb1 libxcb1-dev libxdmcp-dev libxdmcp6\n",
      "  libxext6 libxrender-dev libxrender1 x11-common x11proto-core-dev\n",
      "  x11proto-dev xorg-sgml-doctools xtrans-dev\n",
      "0 upgraded, 22 newly installed, 0 to remove and 13 not upgraded.\n",
      "Need to get 3243 kB/4102 kB of archives.\n",
      "After this operation, 19.9 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libice6 amd64 2:1.0.9-2 [40.2 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsm6 amd64 2:1.2.2-1 [15.8 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpthread-stubs0-dev amd64 0.3-4 [4068 B]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 xorg-sgml-doctools all 1:1.11-1 [12.9 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-dev all 2018.4-4 [251 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-core-dev all 2018.4-4 [2620 B]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxau-dev amd64 1:1.0.8-1 [11.1 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxdmcp-dev amd64 1:1.1.2-3 [25.1 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 xtrans-dev all 1.3.5-1 [70.5 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb1-dev amd64 1.13-2~ubuntu18.04 [80.0 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libx11-dev amd64 2:1.6.4-3ubuntu0.2 [640 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libx11-doc all 2:1.6.4-3ubuntu0.2 [2065 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrender-dev amd64 1:0.9.10-1 [24.9 kB]\n",
      "Fetched 3243 kB in 1s (2581 kB/s)                     \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package libxau6:amd64.\n",
      "(Reading database ... 17264 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libxau6_1%3a1.0.8-1_amd64.deb ...\n",
      "Unpacking libxau6:amd64 (1:1.0.8-1) ...\n",
      "Selecting previously unselected package libbsd0:amd64.\n",
      "Preparing to unpack .../01-libbsd0_0.8.7-1_amd64.deb ...\n",
      "Unpacking libbsd0:amd64 (0.8.7-1) ...\n",
      "Selecting previously unselected package libxdmcp6:amd64.\n",
      "Preparing to unpack .../02-libxdmcp6_1%3a1.1.2-3_amd64.deb ...\n",
      "Unpacking libxdmcp6:amd64 (1:1.1.2-3) ...\n",
      "Selecting previously unselected package libxcb1:amd64.\n",
      "Preparing to unpack .../03-libxcb1_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb1:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libx11-data.\n",
      "Preparing to unpack .../04-libx11-data_2%3a1.6.4-3ubuntu0.2_all.deb ...\n",
      "Unpacking libx11-data (2:1.6.4-3ubuntu0.2) ...\n",
      "Selecting previously unselected package libx11-6:amd64.\n",
      "Preparing to unpack .../05-libx11-6_2%3a1.6.4-3ubuntu0.2_amd64.deb ...\n",
      "Unpacking libx11-6:amd64 (2:1.6.4-3ubuntu0.2) ...\n",
      "Selecting previously unselected package libxext6:amd64.\n",
      "Preparing to unpack .../06-libxext6_2%3a1.3.3-1_amd64.deb ...\n",
      "Unpacking libxext6:amd64 (2:1.3.3-1) ...\n",
      "Selecting previously unselected package x11-common.\n",
      "Preparing to unpack .../07-x11-common_1%3a7.7+19ubuntu7.1_all.deb ...\n",
      "dpkg-query: no packages found matching nux-tools\n",
      "Unpacking x11-common (1:7.7+19ubuntu7.1) ...\n",
      "Selecting previously unselected package libice6:amd64.\n",
      "Preparing to unpack .../08-libice6_2%3a1.0.9-2_amd64.deb ...\n",
      "Unpacking libice6:amd64 (2:1.0.9-2) ...\n",
      "Selecting previously unselected package libsm6:amd64.\n",
      "Preparing to unpack .../09-libsm6_2%3a1.2.2-1_amd64.deb ...\n",
      "Unpacking libsm6:amd64 (2:1.2.2-1) ...\n",
      "Selecting previously unselected package libpthread-stubs0-dev:amd64.\n",
      "Preparing to unpack .../10-libpthread-stubs0-dev_0.3-4_amd64.deb ...\n",
      "Unpacking libpthread-stubs0-dev:amd64 (0.3-4) ...\n",
      "Selecting previously unselected package xorg-sgml-doctools.\n",
      "Preparing to unpack .../11-xorg-sgml-doctools_1%3a1.11-1_all.deb ...\n",
      "Unpacking xorg-sgml-doctools (1:1.11-1) ...\n",
      "Selecting previously unselected package x11proto-dev.\n",
      "Preparing to unpack .../12-x11proto-dev_2018.4-4_all.deb ...\n",
      "Unpacking x11proto-dev (2018.4-4) ...\n",
      "Selecting previously unselected package x11proto-core-dev.\n",
      "Preparing to unpack .../13-x11proto-core-dev_2018.4-4_all.deb ...\n",
      "Unpacking x11proto-core-dev (2018.4-4) ...\n",
      "Selecting previously unselected package libxau-dev:amd64.\n",
      "Preparing to unpack .../14-libxau-dev_1%3a1.0.8-1_amd64.deb ...\n",
      "Unpacking libxau-dev:amd64 (1:1.0.8-1) ...\n",
      "Selecting previously unselected package libxdmcp-dev:amd64.\n",
      "Preparing to unpack .../15-libxdmcp-dev_1%3a1.1.2-3_amd64.deb ...\n",
      "Unpacking libxdmcp-dev:amd64 (1:1.1.2-3) ...\n",
      "Selecting previously unselected package xtrans-dev.\n",
      "Preparing to unpack .../16-xtrans-dev_1.3.5-1_all.deb ...\n",
      "Unpacking xtrans-dev (1.3.5-1) ...\n",
      "Selecting previously unselected package libxcb1-dev:amd64.\n",
      "Preparing to unpack .../17-libxcb1-dev_1.13-2~ubuntu18.04_amd64.deb ...\n",
      "Unpacking libxcb1-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Selecting previously unselected package libx11-dev:amd64.\n",
      "Preparing to unpack .../18-libx11-dev_2%3a1.6.4-3ubuntu0.2_amd64.deb ...\n",
      "Unpacking libx11-dev:amd64 (2:1.6.4-3ubuntu0.2) ...\n",
      "Selecting previously unselected package libx11-doc.\n",
      "Preparing to unpack .../19-libx11-doc_2%3a1.6.4-3ubuntu0.2_all.deb ...\n",
      "Unpacking libx11-doc (2:1.6.4-3ubuntu0.2) ...\n",
      "Selecting previously unselected package libxrender1:amd64.\n",
      "Preparing to unpack .../20-libxrender1_1%3a0.9.10-1_amd64.deb ...\n",
      "Unpacking libxrender1:amd64 (1:0.9.10-1) ...\n",
      "Selecting previously unselected package libxrender-dev:amd64.\n",
      "Preparing to unpack .../21-libxrender-dev_1%3a0.9.10-1_amd64.deb ...\n",
      "Unpacking libxrender-dev:amd64 (1:0.9.10-1) ...\n",
      "Setting up libpthread-stubs0-dev:amd64 (0.3-4) ...\n",
      "Setting up xorg-sgml-doctools (1:1.11-1) ...\n",
      "Setting up libbsd0:amd64 (0.8.7-1) ...\n",
      "Setting up x11proto-dev (2018.4-4) ...\n",
      "Setting up xtrans-dev (1.3.5-1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "Setting up libx11-doc (2:1.6.4-3ubuntu0.2) ...\n",
      "Setting up libxdmcp6:amd64 (1:1.1.2-3) ...\n",
      "Setting up x11-common (1:7.7+19ubuntu7.1) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
      "debconf: falling back to frontend: Readline\n",
      "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "Setting up libx11-data (2:1.6.4-3ubuntu0.2) ...\n",
      "Setting up libxau6:amd64 (1:1.0.8-1) ...\n",
      "Setting up x11proto-core-dev (2018.4-4) ...\n",
      "Setting up libxau-dev:amd64 (1:1.0.8-1) ...\n",
      "Setting up libxdmcp-dev:amd64 (1:1.1.2-3) ...\n",
      "Setting up libice6:amd64 (2:1.0.9-2) ...\n",
      "Setting up libxcb1:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libsm6:amd64 (2:1.2.2-1) ...\n",
      "Setting up libx11-6:amd64 (2:1.6.4-3ubuntu0.2) ...\n",
      "Setting up libxrender1:amd64 (1:0.9.10-1) ...\n",
      "Setting up libxcb1-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
      "Setting up libx11-dev:amd64 (2:1.6.4-3ubuntu0.2) ...\n",
      "Setting up libxext6:amd64 (2:1.3.3-1) ...\n",
      "Setting up libxrender-dev:amd64 (1:0.9.10-1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "Collecting opencv-python\n",
      "  Using cached https://files.pythonhosted.org/packages/5e/7e/bd5425f4dacb73367fddc71388a47c1ea570839197c2bcad86478e565186/opencv_python-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting numpy>=1.11.3 (from opencv-python)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/e6/c3fdc53aed9fa19d6ff3abf97dfad768ae3afce1b7431f7500000816bda5/numpy-1.17.2-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n",
      "\u001b[K     |████████████████████████████████| 20.4MB 10.5MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy, opencv-python\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed numpy-1.17.2 opencv-python-4.1.1.26\r\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y libsm6 libxext6 libxrender-dev\n",
    "!pip install opencv-python --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: progressbar in /usr/local/lib/python3.6/dist-packages (2.5)\n",
      "Collecting glob3\n",
      "  Downloading https://files.pythonhosted.org/packages/d6/21/e042ea7bcb917bac5cf2365d532d44efc23650be81456546a6e89e25371e/glob3-0.0.1.tar.gz\n",
      "Building wheels for collected packages: glob3\n",
      "  Building wheel for glob3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for glob3: filename=glob3-0.0.1-cp36-none-any.whl size=2411 sha256=269d64b53ee52c228b85c603ac44fad90349437fcd2a8f1e2de7f9436c47ebde\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/db/36/aae4683ac0ba95eb154510b48d6bda87fbaac71b6a9b62123d\n",
      "Successfully built glob3\n",
      "Installing collected packages: glob3\n",
      "Successfully installed glob3-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install progressbar2 glob3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcHqdWBNZdcr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Try to fix images (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYR3QDZ4Zdcs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import progressbar\n",
    "import glob\n",
    "\n",
    "img_dirs = ['/home/TF_object_detection/data/images/test', '/home/TF_object_detection/data/images/train']\n",
    "for dir in img_dirs:\n",
    "    os.chdir(dir)\n",
    "    for img in glob.glob('*.jpg'):\n",
    "        cv2.imwrite(img, cv2.imread(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bI8__uNS8-ns"
   },
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ecpHEnka8Kix"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Failed to fetch http://archive.ubuntu.com/ubuntu/pool/main/p/python2.7/libpython2.7-minimal_2.7.15-4ubuntu4~18.04_amd64.deb  404  Not Found [IP: 91.189.88.173 80]\n",
      "E: Failed to fetch http://archive.ubuntu.com/ubuntu/pool/main/p/python2.7/python2.7-minimal_2.7.15-4ubuntu4~18.04_amd64.deb  404  Not Found [IP: 91.189.88.173 80]\n",
      "E: Failed to fetch http://archive.ubuntu.com/ubuntu/pool/main/p/python2.7/libpython2.7-stdlib_2.7.15-4ubuntu4~18.04_amd64.deb  404  Not Found [IP: 91.189.88.173 80]\n",
      "E: Failed to fetch http://archive.ubuntu.com/ubuntu/pool/main/p/python2.7/python2.7_2.7.15-4ubuntu4~18.04_amd64.deb  404  Not Found [IP: 91.189.88.173 80]\n",
      "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/t/tzdata/tzdata_2019a-0ubuntu0.18.04_all.deb  404  Not Found [IP: 91.189.88.173 80]\n",
      "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n",
      "/home/TensorFlow/models/research\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0913 11:02:56.687511 140443908642624 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0913 11:02:56.775209 140443908642624 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0913 11:02:56.784221 140443908642624 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "Running tests under Python 3.6.8: /usr/local/bin/python\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
      "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
      "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
      "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
      "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTest.test_session\n",
      "[  SKIPPED ] ModelBuilderTest.test_session\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
      "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
      "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
      "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 16 tests in 0.210s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "# %cd /content\n",
    "# !git clone --quiet https://github.com/tensorflow/models.git\n",
    "\n",
    "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
    "\n",
    "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
    "\n",
    "!pip install -q pycocotools\n",
    "\n",
    "%cd /home/TensorFlow/models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONPATH'] += ':/home/TensorFlow/models/research/:/home/TensorFlow/models/research/slim/'\n",
    "\n",
    "!python object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-k7uGThXlny"
   },
   "source": [
    "## Prepare `tfrecord` files\n",
    "\n",
    "Use the following scripts to generate the `tfrecord` files.\n",
    "```bash\n",
    "# Convert train folder annotation xml files to a single csv file,\n",
    "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
    "python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
    "\n",
    "# Convert test folder annotation xml files to a single csv.\n",
    "python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
    "\n",
    "# Generate `train.record`\n",
    "python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
    "\n",
    "# Generate `test.record`\n",
    "python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ezGDABRXXhPP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/TF_object_detection\n",
      "Successfully converted xml to csv.\n",
      "Generate `data/annotations/label_map.pbtxt`\n",
      "Successfully converted xml to csv.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "W0913 11:03:10.635046 140186697754432 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/utils/label_map_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "Successfully created the TFRecords: /home/TF_object_detection/data/annotations/train.record\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "W0913 11:03:15.996063 140089542055744 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/utils/label_map_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "Successfully created the TFRecords: /home/TF_object_detection/data/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "repo_dir_path = '/home/TF_object_detection/'\n",
    "%cd {repo_dir_path}\n",
    "\n",
    "# Convert train folder annotation xml files to a single csv file,\n",
    "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
    "!python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
    "\n",
    "# Convert test folder annotation xml files to a single csv.\n",
    "!python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
    "\n",
    "# Generate `train.record`\n",
    "!python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
    "\n",
    "# Generate `test.record`\n",
    "!python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tgd-fzAIkZlV"
   },
   "outputs": [],
   "source": [
    "test_record_fname = '/home/TF_object_detection/data/annotations/test.record'\n",
    "train_record_fname = '/home/TF_object_detection/data/annotations/train.record'\n",
    "label_map_pbtxt_fname = '/home/TF_object_detection/data/annotations/label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCNYAaC7w6N8"
   },
   "source": [
    "## Download base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "orDCj6ihgUMR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/TensorFlow/models/research\n"
     ]
    }
   ],
   "source": [
    "%cd /home/TensorFlow/models/research\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import urllib.request\n",
    "import tarfile\n",
    "MODEL_FILE = MODEL + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "DEST_DIR = '/home/TensorFlow/models/research/pretrained_model'\n",
    "\n",
    "if not (os.path.exists(MODEL_FILE)):\n",
    "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "\n",
    "tar = tarfile.open(MODEL_FILE)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "os.remove(MODEL_FILE)\n",
    "if (os.path.exists(DEST_DIR)):\n",
    "    shutil.rmtree(DEST_DIR)\n",
    "os.rename(MODEL, DEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pGhvAObeiIix"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/TensorFlow/models/research/pretrained_model\n",
      "total 111M\n",
      "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 .\n",
      "drwxr-xr-x 71   1000 1000 4.0K Sep 13 11:03 ..\n",
      "-rw-r--r--  1 345018 5000   77 Feb  1  2018 checkpoint\n",
      "-rw-r--r--  1 345018 5000  55M Feb  1  2018 frozen_inference_graph.pb\n",
      "-rw-r--r--  1 345018 5000  51M Feb  1  2018 model.ckpt.data-00000-of-00001\n",
      "-rw-r--r--  1 345018 5000  16K Feb  1  2018 model.ckpt.index\n",
      "-rw-r--r--  1 345018 5000 5.5M Feb  1  2018 model.ckpt.meta\n",
      "-rw-r--r--  1 345018 5000 3.2K Feb  1  2018 pipeline.config\n",
      "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 saved_model\n"
     ]
    }
   ],
   "source": [
    "!echo {DEST_DIR}\n",
    "!ls -alh {DEST_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UHnxlfRznPP3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/TensorFlow/models/research/pretrained_model/model.ckpt'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
    "fine_tune_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvwtHlLOeRJD"
   },
   "source": [
    "## Configuring a Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIhw7IdpLuiU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "pipeline_fname = os.path.join('/home/TensorFlow/models/research/object_detection/samples/configs/', pipeline_file)\n",
    "# pipeline_fname = '/home/TF_object_detection/adam_pipeline.config'\n",
    "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG1nCNpUXcRU"
   },
   "outputs": [],
   "source": [
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YjtCbLF2i0wI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0913 11:04:03.753330 140096704145216 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/utils/label_map_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "with open(pipeline_fname, 'w') as f:\n",
    "    \n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "    \n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
    "\n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "    \n",
    "#     # Set the input tensor size\n",
    "    s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n",
    "    s = re.sub('min_dimension: [0-9]+', 'height: {}'.format(600), s)\n",
    "    s = re.sub('max_dimension: [0-9]+', 'width: {}'.format(1024), s)\n",
    "    \n",
    "    # Set the example number\n",
    "    s = re.sub('num_examples: [0-9]+', 'num_examples: 4000', s)\n",
    "\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GH0MEEanocn6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Faster R-CNN with Inception v2, configured for Oxford-IIIT Pets Dataset.\r\n",
      "# Users should configure the fine_tune_checkpoint field in the train config as\r\n",
      "# well as the label_map_path and input_path fields in the train_input_reader and\r\n",
      "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\r\n",
      "# should be configured.\r\n",
      "\r\n",
      "model {\r\n",
      "  faster_rcnn {\r\n",
      "    num_classes: 2\r\n",
      "    image_resizer {\r\n",
      "      keep_aspect_ratio_resizer {\r\n",
      "        min_dimension: 600\r\n",
      "        max_dimension: 1024\r\n",
      "      }\r\n",
      "    }\r\n",
      "    feature_extractor {\r\n",
      "      type: 'faster_rcnn_inception_v2'\r\n",
      "      first_stage_features_stride: 16\r\n",
      "    }\r\n",
      "    first_stage_anchor_generator {\r\n",
      "      grid_anchor_generator {\r\n",
      "        scales: [0.25, 0.5, 1.0, 2.0]\r\n",
      "        aspect_ratios: [0.5, 1.0, 2.0]\r\n",
      "        height_stride: 16\r\n",
      "        width_stride: 16\r\n",
      "      }\r\n",
      "    }\r\n",
      "    first_stage_box_predictor_conv_hyperparams {\r\n",
      "      op: CONV\r\n",
      "      regularizer {\r\n",
      "        l2_regularizer {\r\n",
      "          weight: 0.0\r\n",
      "        }\r\n",
      "      }\r\n",
      "      initializer {\r\n",
      "        truncated_normal_initializer {\r\n",
      "          stddev: 0.01\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "    first_stage_nms_score_threshold: 0.0\r\n",
      "    first_stage_nms_iou_threshold: 0.7\r\n",
      "    first_stage_max_proposals: 300\r\n",
      "    first_stage_localization_loss_weight: 2.0\r\n",
      "    first_stage_objectness_loss_weight: 1.0\r\n",
      "    initial_crop_size: 14\r\n",
      "    maxpool_kernel_size: 2\r\n",
      "    maxpool_stride: 2\r\n",
      "    second_stage_box_predictor {\r\n",
      "      mask_rcnn_box_predictor {\r\n",
      "        use_dropout: false\r\n",
      "        dropout_keep_probability: 1.0\r\n",
      "        fc_hyperparams {\r\n",
      "          op: FC\r\n",
      "          regularizer {\r\n",
      "            l2_regularizer {\r\n",
      "              weight: 0.0\r\n",
      "            }\r\n",
      "          }\r\n",
      "          initializer {\r\n",
      "            variance_scaling_initializer {\r\n",
      "              factor: 1.0\r\n",
      "              uniform: true\r\n",
      "              mode: FAN_AVG\r\n",
      "            }\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "    second_stage_post_processing {\r\n",
      "      batch_non_max_suppression {\r\n",
      "        score_threshold: 0.0\r\n",
      "        iou_threshold: 0.6\r\n",
      "        max_detections_per_class: 100\r\n",
      "        max_total_detections: 300\r\n",
      "      }\r\n",
      "      score_converter: SOFTMAX\r\n",
      "    }\r\n",
      "    second_stage_localization_loss_weight: 2.0\r\n",
      "    second_stage_classification_loss_weight: 1.0\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "train_config: {\r\n",
      "  batch_size: 12\r\n",
      "  optimizer {\r\n",
      "    momentum_optimizer: {\r\n",
      "      learning_rate: {\r\n",
      "        manual_step_learning_rate {\r\n",
      "          initial_learning_rate: 0.0002\r\n",
      "          schedule {\r\n",
      "            step: 900000\r\n",
      "            learning_rate: .00002\r\n",
      "          }\r\n",
      "          schedule {\r\n",
      "            step: 1200000\r\n",
      "            learning_rate: .000002\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "      momentum_optimizer_value: 0.9\r\n",
      "    }\r\n",
      "    use_moving_average: false\r\n",
      "  }\r\n",
      "  gradient_clipping_by_norm: 10.0\r\n",
      "  fine_tune_checkpoint: \"/home/TensorFlow/models/research/pretrained_model/model.ckpt\"\r\n",
      "  from_detection_checkpoint: true\r\n",
      "  load_all_detection_checkpoint_vars: true\r\n",
      "  # Note: The below line limits the training process to 200K steps, which we\r\n",
      "  # empirically found to be sufficient enough to train the pets dataset. This\r\n",
      "  # effectively bypasses the learning rate schedule (the learning rate will\r\n",
      "  # never decay). Remove the below line to train indefinitely.\r\n",
      "  num_steps: 40000\r\n",
      "  data_augmentation_options {\r\n",
      "    random_horizontal_flip {\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "\r\n",
      "train_input_reader: {\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"/home/TF_object_detection/data/annotations/train.record\"\r\n",
      "  }\r\n",
      "  label_map_path: \"/home/TF_object_detection/data/annotations/label_map.pbtxt\"\r\n",
      "}\r\n",
      "\r\n",
      "eval_config: {\r\n",
      "  metrics_set: \"coco_detection_metrics\"\r\n",
      "  num_examples: 4000\r\n",
      "}\r\n",
      "\r\n",
      "eval_input_reader: {\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"/home/TF_object_detection/data/annotations/test.record\"\r\n",
      "  }\r\n",
      "  label_map_path: \"/home/TF_object_detection/data/annotations/label_map.pbtxt\"\r\n",
      "  shuffle: false\r\n",
      "  num_readers: 1\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!cat {pipeline_fname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f11w0uO3jFCB"
   },
   "outputs": [],
   "source": [
    "# model_dir = 'training/'\n",
    "model_dir = '/home/FasterRCNN_inV2_pigeon/training/'\n",
    "# Optionally remove content in output model directory to fresh start.\n",
    "!rm -rf \"{model_dir}\"\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "23TECXvNezIF"
   },
   "source": [
    "## Run Tensorboard(Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0H2PZs-mSCmO"
   },
   "outputs": [],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip -o ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G8o6r1o5SC5M"
   },
   "outputs": [],
   "source": [
    "LOG_DIR = model_dir\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ge1OX7gcSC7S"
   },
   "outputs": [],
   "source": [
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m5GSGxZNh8rp"
   },
   "source": [
    "### Get Tensorboard link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjhPT9iPSJ6T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"<string>\", line 1, in <module>\r\n",
      "  File \"/usr/lib/python3.6/json/__init__.py\", line 299, in load\r\n",
      "    parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\r\n",
      "  File \"/usr/lib/python3.6/json/__init__.py\", line 354, in loads\r\n",
      "    return _default_decoder.decode(s)\r\n",
      "  File \"/usr/lib/python3.6/json/decoder.py\", line 339, in decode\r\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\r\n",
      "  File \"/usr/lib/python3.6/json/decoder.py\", line 357, in raw_decode\r\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\r\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\r\n"
     ]
    }
   ],
   "source": [
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JDddx2rPfex9"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CjDHjhKQofT5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0913 11:04:41.975997 140237836339008 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0913 11:04:41.993276 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0913 11:04:42.001347 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0913 11:04:42.037204 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "W0913 11:04:42.038170 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0913 11:04:42.043189 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/model_lib.py:616: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "W0913 11:04:42.043664 140237836339008 model_lib.py:617] Forced number of epochs for all eval validations to be 1.\n",
      "W0913 11:04:42.043881 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "I0913 11:04:42.043934 140237836339008 config_util.py:488] Maybe overwriting train_steps: 40000\n",
      "I0913 11:04:42.044017 140237836339008 config_util.py:488] Maybe overwriting use_bfloat16: False\n",
      "I0913 11:04:42.044068 140237836339008 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "I0913 11:04:42.044132 140237836339008 config_util.py:488] Maybe overwriting eval_num_epochs: 1\n",
      "I0913 11:04:42.044176 140237836339008 config_util.py:488] Maybe overwriting load_pretrained: True\n",
      "I0913 11:04:42.044222 140237836339008 config_util.py:498] Ignoring config override key: load_pretrained\n",
      "W0913 11:04:42.045219 140237836339008 model_lib.py:633] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "I0913 11:04:42.045361 140237836339008 model_lib.py:668] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
      "I0913 11:04:42.046388 140237836339008 estimator.py:209] Using config: {'_model_dir': '/home/FasterRCNN_inV2_pigeon/training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8b3bbbf160>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "W0913 11:04:42.046583 140237836339008 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f8b3bbc5488>) includes params argument, but params are not passed to Estimator.\n",
      "I0913 11:04:42.047231 140237836339008 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "I0913 11:04:42.047396 140237836339008 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "I0913 11:04:42.047566 140237836339008 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "W0913 11:04:42.053401 140237836339008 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0913 11:04:42.068809 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "W0913 11:04:42.068959 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "W0913 11:04:42.084918 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
      "\n",
      "W0913 11:04:42.085958 140237836339008 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
      "W0913 11:04:42.091815 140237836339008 deprecation.py:323] From /home/TensorFlow/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "W0913 11:04:42.092009 140237836339008 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W0913 11:04:42.133146 140237836339008 deprecation.py:323] From /home/TensorFlow/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0913 11:04:42.283391 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/utils/ops.py:491: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n",
      "W0913 11:04:42.286599 140237836339008 deprecation.py:323] From /home/TensorFlow/models/research/object_detection/utils/ops.py:493: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0913 11:04:42.326427 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/core/preprocessor.py:626: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0913 11:04:42.360018 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/core/preprocessor.py:2412: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "W0913 11:04:42.721897 140237836339008 deprecation.py:323] From /home/TensorFlow/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
      "I0913 11:04:42.734334 140237836339008 estimator.py:1145] Calling model_fn.\n",
      "W0913 11:04:42.886045 140237836339008 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "I0913 11:04:44.585374 140237836339008 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "I0913 11:04:44.597471 140237836339008 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "I0913 11:04:44.597715 140237836339008 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "W0913 11:04:47.675126 140237836339008 deprecation.py:506] From /home/TensorFlow/models/research/object_detection/utils/spatial_transform_ops.py:418: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "W0913 11:04:48.081079 140237836339008 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "I0913 11:04:48.222878 140237836339008 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "I0913 11:04:48.419345 140237836339008 regularizers.py:98] Scale of 0 disables regularizer.\n",
      "W0913 11:04:48.477859 140237836339008 deprecation.py:323] From /home/TensorFlow/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2650: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "W0913 11:04:48.478741 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
      "\n",
      "W0913 11:04:48.482842 140237836339008 variables_helper.py:154] Variable [SecondStageBoxPredictor/BoxEncodingPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[360]], model variable shape: [[8]]. This variable will not be initialized from the checkpoint.\n",
      "W0913 11:04:48.482965 140237836339008 variables_helper.py:154] Variable [SecondStageBoxPredictor/BoxEncodingPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1024, 360]], model variable shape: [[1024, 8]]. This variable will not be initialized from the checkpoint.\n",
      "W0913 11:04:48.483035 140237836339008 variables_helper.py:154] Variable [SecondStageBoxPredictor/ClassPredictor/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[91]], model variable shape: [[3]]. This variable will not be initialized from the checkpoint.\n",
      "W0913 11:04:48.483085 140237836339008 variables_helper.py:154] Variable [SecondStageBoxPredictor/ClassPredictor/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1024, 91]], model variable shape: [[1024, 3]]. This variable will not be initialized from the checkpoint.\n",
      "W0913 11:04:48.483854 140237836339008 variables_helper.py:157] Variable [global_step] is not available in checkpoint\n",
      "W0913 11:04:48.484078 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/model_lib.py:345: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "W0913 11:04:51.232321 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
      "\n",
      "W0913 11:04:51.233193 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
      "\n",
      "W0913 11:04:51.267268 140237836339008 deprecation.py:323] From /home/TensorFlow/models/research/object_detection/core/losses.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0913 11:04:52.616189 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/model_lib.py:372: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "W0913 11:04:52.621782 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "W0913 11:04:52.621904 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/model_lib.py:400: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "W0913 11:04:56.795875 140237836339008 deprecation_wrapper.py:119] From /home/TensorFlow/models/research/object_detection/model_lib.py:503: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "I0913 11:04:57.113131 140237836339008 estimator.py:1147] Done calling model_fn.\n",
      "I0913 11:04:57.114053 140237836339008 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0913 11:04:59.861858 140237836339008 monitored_session.py:240] Graph was finalized.\n",
      "2019-09-13 11:04:59.862089: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-09-13 11:04:59.865842: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2019-09-13 11:04:59.960570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-09-13 11:04:59.968206: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x63c8ba0 executing computations on platform CUDA. Devices:\n",
      "2019-09-13 11:04:59.968218: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2019-09-13 11:04:59.987001: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz\n",
      "2019-09-13 11:04:59.987808: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6540a00 executing computations on platform Host. Devices:\n",
      "2019-09-13 11:04:59.987820: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-09-13 11:04:59.987991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-09-13 11:04:59.988426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.721\n",
      "pciBusID: 0000:01:00.0\n",
      "2019-09-13 11:04:59.988651: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-09-13 11:04:59.990857: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-09-13 11:04:59.991959: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-09-13 11:04:59.992999: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-09-13 11:04:59.995159: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-09-13 11:04:59.996092: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-09-13 11:04:59.999534: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-09-13 11:04:59.999621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-09-13 11:05:00.000130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-09-13 11:05:00.000547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-09-13 11:05:00.000574: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-09-13 11:05:00.001310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-09-13 11:05:00.001320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-09-13 11:05:00.001325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-09-13 11:05:00.001400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-09-13 11:05:00.001887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-09-13 11:05:00.002346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10479 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2019-09-13 11:05:02.725540: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "I0913 11:05:02.770611 140237836339008 session_manager.py:500] Running local_init_op.\n",
      "I0913 11:05:03.001747 140237836339008 session_manager.py:502] Done running local_init_op.\n",
      "I0913 11:05:11.589923 140237836339008 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /home/FasterRCNN_inV2_pigeon/training/model.ckpt.\n",
      "2019-09-13 11:05:19.366437: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-09-13 11:05:21.467753: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1356, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1341, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1429, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\n",
      "  (0) Invalid argument: assertion failed: [maximum box coordinate value is larger than 1.100000: ] [1.49833333]\n",
      "\t [[{{node Loss/ToAbsoluteCoordinates_8/Assert/AssertGuard/Assert}}]]\n",
      "\t [[BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater/_5829]]\n",
      "  (1) Invalid argument: assertion failed: [maximum box coordinate value is larger than 1.100000: ] [1.49833333]\n",
      "\t [[{{node Loss/ToAbsoluteCoordinates_8/Assert/AssertGuard/Assert}}]]\n",
      "0 successful operations.\n",
      "0 derived errors ignored.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/TensorFlow/models/research/object_detection/model_main.py\", line 109, in <module>\n",
      "    tf.app.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/home/TensorFlow/models/research/object_detection/model_main.py\", line 105, in main\n",
      "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    return executor.run()\r\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\r\n",
      "    return self.run_local()\r\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\r\n",
      "    saving_listeners=saving_listeners)\r\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 367, in train\r\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model\r\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1192, in _train_model_default\r\n",
      "    saving_listeners)\r\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1484, in _train_with_estimator_spec\r\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 754, in run\r\n",
      "    run_metadata=run_metadata)\r\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1252, in run\r\n",
      "    run_metadata=run_metadata)\r\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1353, in run\r\n",
      "    raise six.reraise(*original_exc_info)\r\n",
      "  File \"/usr/lib/python3/dist-packages/six.py\", line 693, in reraise\r\n",
      "    raise value\r\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1338, in run\r\n",
      "    return self._sess.run(*args, **kwargs)\r\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1411, in run\r\n",
      "    run_metadata=run_metadata)\r\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1169, in run\r\n",
      "    return self._sess.run(*args, **kwargs)\r\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 950, in run\r\n",
      "    run_metadata_ptr)\r\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1173, in _run\r\n",
      "    feed_dict_tensor, options, run_metadata)\r\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1350, in _do_run\r\n",
      "    run_metadata)\r\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1370, in _do_call\r\n",
      "    raise type(e)(node_def, op, message)\r\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n",
      "  (0) Invalid argument: assertion failed: [maximum box coordinate value is larger than 1.100000: ] [1.49833333]\r\n",
      "\t [[node Loss/ToAbsoluteCoordinates_8/Assert/AssertGuard/Assert (defined at home/TensorFlow/models/research/object_detection/core/box_list_ops.py:844) ]]\r\n",
      "\t [[BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater/_5829]]\r\n",
      "  (1) Invalid argument: assertion failed: [maximum box coordinate value is larger than 1.100000: ] [1.49833333]\r\n",
      "\t [[node Loss/ToAbsoluteCoordinates_8/Assert/AssertGuard/Assert (defined at home/TensorFlow/models/research/object_detection/core/box_list_ops.py:844) ]]\r\n",
      "0 successful operations.\r\n",
      "0 derived errors ignored.\r\n",
      "\r\n",
      "Original stack trace for 'Loss/ToAbsoluteCoordinates_8/Assert/AssertGuard/Assert':\r\n",
      "  File \"home/TensorFlow/models/research/object_detection/model_main.py\", line 109, in <module>\r\n",
      "    tf.app.run()\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\r\n",
      "    _run_main(main, args)\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\r\n",
      "    sys.exit(main(argv))\r\n",
      "  File \"home/TensorFlow/models/research/object_detection/model_main.py\", line 105, in main\r\n",
      "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\r\n",
      "    return executor.run()\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\r\n",
      "    return self.run_local()\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\r\n",
      "    saving_listeners=saving_listeners)\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 367, in train\r\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model\r\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1188, in _train_model_default\r\n",
      "    features, labels, ModeKeys.TRAIN, self.config)\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1146, in _call_model_fn\r\n",
      "    model_fn_results = self._model_fn(features=features, **kwargs)\r\n",
      "  File \"home/TensorFlow/models/research/object_detection/model_lib.py\", line 350, in model_fn\r\n",
      "    prediction_dict, features[fields.InputDataFields.true_image_shape])\r\n",
      "  File \"home/TensorFlow/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 2074, in loss\r\n",
      "    ) = self._format_groundtruth_data(true_image_shapes)\r\n",
      "  File \"home/TensorFlow/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 1741, in _format_groundtruth_data\r\n",
      "    self.groundtruth_lists(fields.BoxListFields.boxes))\r\n",
      "  File \"home/TensorFlow/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py\", line 1740, in <listcomp>\r\n",
      "    for i, boxes in enumerate(\r\n",
      "  File \"home/TensorFlow/models/research/object_detection/core/box_list_ops.py\", line 844, in to_absolute_coordinates\r\n",
      "    'than %f: ' % maximum_normalized_coordinate, box_maximum])\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\r\n",
      "    return _add_should_use_warning(fn(*args, **kwargs))\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 171, in Assert\r\n",
      "    guarded_assert = cond(condition, no_op, true_assert, name=\"AssertGuard\")\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n",
      "    return func(*args, **kwargs)\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1988, in cond\r\n",
      "    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1814, in BuildCondBranch\r\n",
      "    original_result = fn()\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 169, in true_assert\r\n",
      "    condition, data, summarize, name=\"Assert\")\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_logging_ops.py\", line 74, in _assert\r\n",
      "    name=name)\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n",
      "    op_def=op_def)\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n",
      "    return func(*args, **kwargs)\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\r\n",
      "    op_def=op_def)\r\n",
      "  File \"usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\r\n",
      "    self._traceback = tf_stack.extract_stack()\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python /home/TensorFlow/models/research/object_detection/model_main.py \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --model_dir='{model_dir}' \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --num_eval_steps={num_eval_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KP-tUdtnRybs"
   },
   "outputs": [],
   "source": [
    "!ls '{model_dir}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1Nrqw3nqnCh"
   },
   "outputs": [],
   "source": [
    "# Legacy way of training(also works).\n",
    "# !python /home/TensorFlow/models/research/object_detection/legacy/train.py --logtostderr --train_dir={model_dir} --pipeline_config_path={pipeline_fname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmSESMetj1sa"
   },
   "source": [
    "## Exporting a Trained Inference Graph\n",
    "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DHoP90pUyKSq"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "output_directory = './fine_tuned_model'\n",
    "\n",
    "lst = os.listdir(model_dir)\n",
    "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
    "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
    "last_model = lst[steps.argmax()].replace('.meta', '')\n",
    "\n",
    "last_model_path = os.path.join(model_dir, last_model)\n",
    "print(last_model_path)\n",
    "!python /home/TensorFlow/models/research/object_detection/export_inference_graph.py \\\n",
    "    --input_type=image_tensor \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --output_directory={output_directory} \\\n",
    "    --trained_checkpoint_prefix='{last_model_path}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "usgBZvkz0nqD"
   },
   "outputs": [],
   "source": [
    "!ls {output_directory}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zip the output directory to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "zip_save_path = '/content/drive/Shared drives/LIS Drone Scarecrow/Bird Detection/TensorFlow Model/trained_models'\n",
    "zip_model_num = last_model.rsplit('-', 1)[1]\n",
    "zip_date = now.strftime(\"%m%d%Y-%H%M%S\")\n",
    "zip_model_name = '{}/inference_graph_{}_{}.zip'.format(zip_save_path, zip_model_num, zip_date)\n",
    "!zip -r '{zip_model_name}' {output_directory}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p09AOThWkaQv"
   },
   "source": [
    "## Download the model `.pb` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CnDo1lonKgFr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
    "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lHqWkLBINYoI"
   },
   "outputs": [],
   "source": [
    "!ls -alh {pb_fname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIqnjbWYsuQw"
   },
   "source": [
    "### Option1 : upload the `.pb` file to your Google Drive\n",
    "Then download it from your Google Drive to local file system.\n",
    "\n",
    "During this step, you will be prompted to enter the token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAqyASIJqjae"
   },
   "outputs": [],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once in a notebook.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "fname = os.path.basename(pb_fname)\n",
    "# Create & upload a text file.\n",
    "uploaded = drive.CreateFile({'title': fname})\n",
    "uploaded.SetContentFile(pb_fname)\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2FKFq8RXs6bs"
   },
   "source": [
    "### Option2 :  Download the `.pb` file directly to your local file system\n",
    "This method may not be stable when downloading large files like the model `.pb` file. Try **option 1** instead if not working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bP0iMMnnr77"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(pb_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MFyCeiBb9BbS"
   },
   "source": [
    "### Download the `label_map.pbtxt` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K1TbL6Ox8q6Z"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(label_map_pbtxt_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iUmAo9foa1xq"
   },
   "source": [
    "### Download the modified pipline file\n",
    "If you plan to use OpenVINO toolkit to convert the `.pb` file to inference faster on Intel's hardware (CPU/GPU, Movidius, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pql2QpemazE1"
   },
   "outputs": [],
   "source": [
    "files.download(pipeline_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1AgBj1l0v_W"
   },
   "outputs": [],
   "source": [
    "# !tar cfz fine_tuned_model.tar.gz fine_tuned_model\n",
    "# from google.colab import files\n",
    "# files.download('fine_tuned_model.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mz1gX19GlVW7"
   },
   "source": [
    "## Run inference test\n",
    "Test with images in repository `TF_object_detection/test` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pzj9A4e5mj5l"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = pb_fname\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = label_map_pbtxt_fname\n",
    "\n",
    "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
    "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"test\")\n",
    "\n",
    "assert os.path.isfile(pb_fname)\n",
    "assert os.path.isfile(PATH_TO_LABELS)\n",
    "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
    "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
    "print(TEST_IMAGE_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CG5YUMdg1Po7"
   },
   "outputs": [],
   "source": [
    "%cd /home/TensorFlow/models/research/object_detection\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)\n",
    "\n",
    "\n",
    "def run_inference_for_single_image(image, graph):\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "            # Get handles to input and output tensors\n",
    "            ops = tf.get_default_graph().get_operations()\n",
    "            all_tensor_names = {\n",
    "                output.name for op in ops for output in op.outputs}\n",
    "            tensor_dict = {}\n",
    "            for key in [\n",
    "                'num_detections', 'detection_boxes', 'detection_scores',\n",
    "                'detection_classes', 'detection_masks'\n",
    "            ]:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensor_names:\n",
    "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                        tensor_name)\n",
    "            if 'detection_masks' in tensor_dict:\n",
    "                # The following processing is only for single image\n",
    "                detection_boxes = tf.squeeze(\n",
    "                    tensor_dict['detection_boxes'], [0])\n",
    "                detection_masks = tf.squeeze(\n",
    "                    tensor_dict['detection_masks'], [0])\n",
    "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "                real_num_detection = tf.cast(\n",
    "                    tensor_dict['num_detections'][0], tf.int32)\n",
    "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
    "                                           real_num_detection, -1])\n",
    "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
    "                                           real_num_detection, -1, -1])\n",
    "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "                detection_masks_reframed = tf.cast(\n",
    "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "                # Follow the convention by adding back the batch dimension\n",
    "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "                    detection_masks_reframed, 0)\n",
    "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "            # Run inference\n",
    "            output_dict = sess.run(tensor_dict,\n",
    "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "            output_dict['num_detections'] = int(\n",
    "                output_dict['num_detections'][0])\n",
    "            output_dict['detection_classes'] = output_dict[\n",
    "                'detection_classes'][0].astype(np.uint8)\n",
    "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "            if 'detection_masks' in output_dict:\n",
    "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "for image_path in TEST_IMAGE_PATHS:\n",
    "    image = Image.open(image_path)\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        output_dict['detection_boxes'],\n",
    "        output_dict['detection_classes'],\n",
    "        output_dict['detection_scores'],\n",
    "        category_index,\n",
    "        instance_masks=output_dict.get('detection_masks'),\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "    plt.figure(figsize=IMAGE_SIZE)\n",
    "    plt.imshow(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GStNeHWPkTcN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tensorflow-object-detection-training-colab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
